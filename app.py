import streamlit as st
import pandas as pd
import uuid

# Import cÃ¡c module tá»± Ä‘á»‹nh nghÄ©a
from src.core.tokenizer import AdvancedTokenizer
from src.core.metrics import BasicMetrics
from src.services.openai_client import get_llm_solution
from src.services.google_sheets import get_gsheet_manager
from src.prompts.taxonomy import PROMPT_TAXONOMY
from src.models.schemas import Run, Suggestion

# --- KHá»I Táº O CÃC Äá»I TÆ¯á»¢NG TOÃ€N Cá»¤C ---
st.set_page_config(layout="wide", page_title="GA Prompting Tool")
tokenizer = AdvancedTokenizer()
metrics_service = BasicMetrics()
gsheet_manager = get_gsheet_manager()

# --- KHá»I Táº O SESSION STATE ---
def init_session_state():
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
        st.session_state.user_id = "user_" + str(uuid.uuid4())[:8] # Giáº£ láº­p user ID
        
    if 'problem_text' not in st.session_state:
        st.session_state.problem_text = "Má»™t hÃ¬nh chá»¯ nháº­t cÃ³ chu vi lÃ  100m. Chiá»u dÃ i hÆ¡n chiá»u rá»™ng 10m. TÃ­nh diá»‡n tÃ­ch cá»§a hÃ¬nh chá»¯ nháº­t."

    if 'current_level' not in st.session_state:
        st.session_state.current_level = 0
        
    if 'current_prompt' not in st.session_state:
        st.session_state.current_prompt = PROMPT_TAXONOMY[0]['template'].format(
            problem_text=st.session_state.problem_text
        )

    # DÃ¹ng Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ cá»§a láº§n cháº¡y gáº§n nháº¥t
    if 'last_run' not in st.session_state:
        st.session_state.last_run = {
            "solution": None,
            "metrics": None,
            "run_id": None
        }
        
    # DÃ¹ng Ä‘á»ƒ lÆ°u trá»¯ baseline Ä‘á»ƒ so sÃ¡nh
    if 'baseline' not in st.session_state:
        st.session_state.baseline = {
            "metrics": None,
            "run_id": None
        }

init_session_state()

# --- HÃ€M Xá»¬ LÃ LOGIC ---
def handle_prompt_submission():
    """Xá»­ lÃ½ khi ngÆ°á»i dÃ¹ng nháº¥n nÃºt 'Gá»­i Prompt'."""
    prompt_text = st.session_state.current_prompt
    if not prompt_text or not prompt_text.strip():
        st.warning("Prompt khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng.")
        return

    with st.spinner("ğŸ¤– AI Ä‘ang suy nghÄ©..."):
        # 1. Gá»i LLM Ä‘á»ƒ láº¥y lá»i giáº£i
        solution_data = get_llm_solution(prompt_text)
        if solution_data["error"]:
            st.error(solution_data["text"])
            return

        # 2. Táº¡o Ä‘á»‘i tÆ°á»£ng Run Ä‘á»ƒ lÆ°u trá»¯
        run_record = Run(
            session_id=st.session_state.session_id,
            user_id=st.session_state.user_id,
            problem_text=st.session_state.problem_text,
            prompt_text=prompt_text,
            prompt_level=st.session_state.current_level,
            model_name="gpt-3.5-turbo",
            response_text=solution_data["text"],
            latency_ms=solution_data["latency_ms"],
            tokens_in=solution_data["tokens_in"],
            tokens_out=solution_data["tokens_out"]
        )
        
        # 3. TÃ­nh toÃ¡n Metrics
        metrics_record = metrics_service.compute(prompt_text, tokenizer, run_id=run_record.run_id)

        # 4. LÆ°u vÃ o Google Sheets
        gsheet_manager.append_data("runs", [run_record])
        gsheet_manager.append_data("metrics", [metrics_record])

        # 5. Cáº­p nháº­t session state
        st.session_state.last_run = {
            "solution": solution_data["text"],
            "metrics": metrics_record,
            "run_id": run_record.run_id
        }

        # 6. Thiáº¿t láº­p baseline náº¿u Ä‘Ã¢y lÃ  láº§n cháº¡y Ä‘áº§u tiÃªn
        if not st.session_state.baseline["metrics"]:
            st.session_state.baseline = {
                "metrics": metrics_record,
                "run_id": run_record.run_id
            }

def apply_suggestion(level):
    """Ãp dá»¥ng template prompt tá»« taxonomy."""
    st.session_state.current_level = level
    st.session_state.current_prompt = PROMPT_TAXONOMY[level]['template'].format(
        problem_text=st.session_state.problem_text
    )
    # Ghi láº¡i sá»± kiá»‡n cháº¥p nháº­n gá»£i Ã½
    suggestion_record = Suggestion(
        session_id=st.session_state.session_id,
        user_id=st.session_state.user_id,
        run_id=st.session_state.last_run['run_id'] or "N/A",
        suggested_level=level,
        accepted=True,
    )
    gsheet_manager.append_data("suggestions", [suggestion_record])


# --- GIAO DIá»†N NGÆ¯á»œI DÃ™NG (UI) ---
st.title("ğŸš€ GA Prompting Gamification Tool (MVP)")
st.caption(f"Session ID: `{st.session_state.session_id}` | User ID: `{st.session_state.user_id}`")

# Cá»™t chÃ­nh: Input vÃ  Output
col1, col2 = st.columns(2)

with col1:
    st.subheader("ğŸ“ Äá» bÃ i")
    st.text_area(
        "Nháº­p Ä‘á» bÃ i toÃ¡n táº¡i Ä‘Ã¢y", 
        key="problem_text",
        height=150,
    )
    
    st.subheader(f"ğŸ’¬ Prompt (Level {st.session_state.current_level}: {PROMPT_TAXONOMY[st.session_state.current_level]['name']})")
    st.text_area(
        "Chá»‰nh sá»­a prompt cá»§a báº¡n",
        key="current_prompt",
        height=250
    )
    st.button("Gá»­i Prompt", type="primary", on_click=handle_prompt_submission)

with col2:
    st.subheader("ğŸ’¡ Lá»i giáº£i tá»« AI")
    solution_container = st.container(height=500, border=True)
    if st.session_state.last_run["solution"]:
        solution_container.markdown(st.session_state.last_run["solution"])
    else:
        solution_container.info("Lá»i giáº£i sáº½ xuáº¥t hiá»‡n á»Ÿ Ä‘Ã¢y sau khi báº¡n gá»­i prompt.")

st.divider()

# HÃ ng thá»© hai: Metrics vÃ  Gá»£i Ã½
col3, col4 = st.columns([0.6, 0.4])

with col3:
    st.subheader("ğŸ“Š PhÃ¢n tÃ­ch Metrics")
    if st.session_state.baseline["metrics"]:
        baseline_metrics = st.session_state.baseline["metrics"]
        current_metrics = st.session_state.last_run["metrics"]

        # TÃ­nh toÃ¡n delta
        mattr_delta = current_metrics.mattr - baseline_metrics.mattr
        reading_ease_delta = current_metrics.reading_ease - baseline_metrics.reading_ease
        token_delta = current_metrics.token_count - baseline_metrics.token_count

        # Táº¡o DataFrame Ä‘á»ƒ hiá»ƒn thá»‹
        data = {
            "Metric": ["Äa dáº¡ng tá»« (MATTR)", "Äá»™ dá»… Ä‘á»c (Reading Ease)", "Sá»‘ Tokens"],
            "Baseline": [
                f"{baseline_metrics.mattr:.3f}",
                f"{baseline_metrics.reading_ease:.1f}/100",
                baseline_metrics.token_count
            ],
            "Hiá»‡n táº¡i": [
                f"{current_metrics.mattr:.3f} ({mattr_delta:+.3f})",
                f"{current_metrics.reading_ease:.1f}/100 ({reading_ease_delta:+.1f})",
                f"{current_metrics.token_count} ({token_delta:+,d})"
            ]
        }
        st.table(pd.DataFrame(data))
    else:
        st.info("Gá»­i prompt Ä‘áº§u tiÃªn Ä‘á»ƒ táº¡o baseline vÃ  xem phÃ¢n tÃ­ch.")

with col4:
    st.subheader("âœ¨ Gá»£i Ã½ cáº£i tiáº¿n")
    next_level = st.session_state.current_level + 1
    if next_level in PROMPT_TAXONOMY:
        suggestion = PROMPT_TAXONOMY[next_level]
        st.markdown(f"**Cáº¥p Ä‘á»™ tiáº¿p theo: {suggestion['name']}**")
        st.info(suggestion['description'])
        
        with st.expander("Xem cáº¥u trÃºc gá»£i Ã½"):
            st.code(suggestion['template'], language='text')

        st.button(
            f"ğŸš€ NÃ¢ng cáº¥p lÃªn Level {next_level}",
            on_click=apply_suggestion,
            args=(next_level,)
        )
    else:
        st.success("ğŸ‰ Báº¡n Ä‘Ã£ á»Ÿ cáº¥p Ä‘á»™ cao nháº¥t! HÃ£y thá»­ nghiá»‡m vá»›i cÃ¡c Ä‘á» bÃ i khÃ¡c.")